{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28142ccc",
   "metadata": {},
   "source": [
    "# Introduction to Programmatic Business Analytics Assignment\n",
    "Utilizing the Bike Sharing Dataset from the UCI Machine Learning Repository, demonstrate your data science and machine learning skills to extract insights and predict bike rental demand. The dataset can be accessed directly via the provided URL and code.\n",
    "\n",
    "In the cell below, we'll import all the packages needed for this assignment. \n",
    "\n",
    "*Make sure you run this cell before proceeding with the rest of the notebook to avoid any import-related errors.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ca28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca373ad5",
   "metadata": {},
   "source": [
    "## Task 1: Data Wrangling and Exploration\n",
    "### 1.1 Load the Dataset\n",
    "Use the provided code to download and extract the dataset directly from the given URL into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3336941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract the dataset\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip'\n",
    "zip_file = requests.get(url)\n",
    "zip_file = ZipFile(BytesIO(zip_file.content))\n",
    "bike_data = pd.read_csv(zip_file.open('day.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e7448",
   "metadata": {},
   "source": [
    "### 1.2 Initial Inspection and Cleaning\n",
    "Perform an initial inspection by methods like head, info, shape to understand the dataset's structure and content.\n",
    "Check for missing values and handle them appropriately, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc9e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a1fce3",
   "metadata": {},
   "source": [
    "### 1.3 data preparation\n",
    "- 1.3.1 Convert dteday to a datetime object.\n",
    "- 1.3.2 Extract year, month, day and daysofweek from dteday and add them as seperate columns to the dataframe.\n",
    "- 1.3.3 Normalize the temp, atemp, hum, and windspeed features using MinMaxScaler\n",
    "- 1.3.4 Encode the season, yr, mnth, holiday, weekday, workingday, and weathersit columns as categorical variables.\n",
    "- 1.3.5 Check the data after the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df376d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ed3d39",
   "metadata": {},
   "source": [
    "### 1.4 visualizing the distribution of bike rentals (cnt) across different time granularities and categorical variables.\n",
    "Conduct a comprehensive exploratory data analysis on the dataset, focusing on the distribution of bike rentals (cnt) across various dimensions and conditions. The analysis should reveal how bike rentals vary over different months, days of the week, seasons, holidays, working days, and weather situations.\n",
    "\n",
    "The analysis should utilize Seaborn for creating visualizations, and these should be organized into a multi-panel figure using Matplotlib's subplot functionality. Each subplot is to represent a different aspect of the data:\n",
    "1. Total bike rentals per month - Presented as a bar plot.\n",
    "2. Total bike rentals per day of the week - Presented as a bar plot.\n",
    "3. Bike rentals distribution per season - Displayed using a box plot.\n",
    "4. Bike rentals on holidays vs. non-holidays - Illustrated with a box plot.\n",
    "5. Bike rentals on working days vs. non-working days - Visualized through a box plot.\n",
    "6. Bike rentals across different weather situations - Depicted with a box plot.\n",
    "\n",
    "All plots should be appropriately titled and laid out for readability and visual appeal. Additionally, a consistent white grid style should be applied to all plots for uniformity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7fbc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeeb718",
   "metadata": {},
   "source": [
    "## Task 2: Statistical Analysis and Predictive Modeling\n",
    "\n",
    "### 2.1 Descriptive and Inferential Statistical Analysis\n",
    "Perform a detailed statistical analysis on a subset of features from the Bike Sharing dataset. The focus should be on understanding the relationships and characteristics of key numerical variables, including temperature (temp), feeling temperature (atemp), humidity (hum), wind speed (windspeed), and total bike rentals (cnt).\n",
    "\n",
    "The following steps should be taken in the analysis:\n",
    "\n",
    "1. Feature Selection: Extract a subset of the dataset containing only the columns temp, atemp, hum, windspeed, and cnt.\n",
    "2. Descriptive Statistics: Generate the descriptive statistics (such as mean, median, standard deviation, etc.) for these selected features. This will provide an overview of the central tendency and spread of the data.\n",
    "3. Inferential Statistics: Compute the correlation matrix for the selected features. This step is essential to understand how these variables are related to each other.\n",
    "4. Visualization of Correlations: Use a heatmap to visualize the correlation matrix. The heatmap should be annotated and utilize a color scheme that clearly indicates the strength and direction of correlations.\n",
    "\n",
    "All analyses and visualizations should be done with attention to detail, ensuring that the outputs are not only accurate but also easy to interpret. The heatmap, in particular, should be sized appropriately for clarity and aesthetic appeal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc6b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e698324",
   "metadata": {},
   "source": [
    "### 2.2 Development and Evaluation of a Linear Regression Model\n",
    "Execute a comprehensive regression analysis on the Bike Sharing dataset to predict bike rental counts (cnt). This task involves selecting relevant features, preparing the data, training a linear regression model, making predictions, and evaluating the model's performance.\n",
    "\n",
    "The detailed steps to be followed in this task are:\n",
    "\n",
    "1. Feature Selection: Choose appropriate predictor variables for the regression model. These should include season, yr (year), mnth (month), holiday, weekday, workingday, weathersit, temp (temperature), atemp (feeling temperature), hum (humidity), and windspeed.\n",
    "2. Data Preparation: Prepare the dataset for training and testing. Assign the selected features to X and the target variable, bike rental counts (cnt), to y. Then, split the dataset into training and testing sets using an 80-20 split ratio and a set random state for reproducibility.\n",
    "3. Model Training: Utilize the Linear Regression algorithm from the scikit-learn library to train the model on the training data.\n",
    "4. Making Predictions: Use the trained model to make predictions on the test dataset.\n",
    "5. Model Evaluation: Evaluate the model's performance by calculating key metrics such as the R^2 Score and Root Mean Squared Error (RMSE). The R^2 Score indicates the proportion of the variance in the dependent variable that is predictable from the independent variables, while RMSE provides a measure of the differences between values predicted by the model and the values actually observed.\n",
    "The outcome of this task should be a well-trained Linear Regression model, along with a thorough evaluation of its predictive performance. All steps should be clearly documented, and findings should be reported with insights drawn from the performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0047a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93c812f",
   "metadata": {},
   "source": [
    "### 2.3 Clustering Analysis\n",
    "Conduct a clustering analysis on the Bike Sharing dataset to uncover patterns and groupings within the environmental variables. The focus will be on the temperature (temp), feeling temperature (atemp), humidity (hum), and wind speed (windspeed) variables. This task involves several key steps, utilizing the KMeans clustering algorithm and evaluating the optimal number of clusters.\n",
    "\n",
    "The analysis should proceed as follows:\n",
    "\n",
    "1. *Feature Selection and Preparation:* Isolate the temp, atemp, hum, and windspeed features for clustering.\n",
    "2. *Data Standardization:* Apply standard scaling to the selected features to normalize their range and variance, ensuring that each feature contributes equally to the clustering process.\n",
    "3. *Determining Optimal Clusters:* Implement the silhouette method to find the optimal number of clusters. This involves running the KMeans algorithm with a varying number of clusters (from 2 to 10) and calculating the silhouette score for each. The silhouette score measures how similar an object is to its own cluster compared to other clusters.\n",
    "4. *Silhouette Score Visualization:* Plot the silhouette scores against the number of clusters to visually determine the optimal cluster count.\n",
    "5. *KMeans Clustering:* Perform KMeans clustering on the standardized data using the optimal number of clusters identified from the silhouette analysis.\n",
    "6. *Integration with Original Data:* Append the cluster labels derived from KMeans to the original dataset, enabling further analysis based on the identified clusters.\n",
    "The expected outcome is a well-defined set of clusters, each representing a unique combination of environmental conditions. The analysis should be presented with clear visualizations, particularly for the silhouette score plot, and detailed explanations of each step and its significance in the overall clustering process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8b3381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4c4377",
   "metadata": {},
   "source": [
    "### 2.4 Visualizing Clustered Bike Rental Data Using Principal Component Analysis\n",
    "Perform a dimensionality reduction and visualization on the previously clustered Bike Sharing dataset to better understand the clustering results. This task involves using Principal Component Analysis (PCA) to reduce the data to two dimensions and then creating a scatter plot to visualize the different clusters.\n",
    "\n",
    "The specific steps to complete this task are:\n",
    "\n",
    "1. Dimensionality Reduction with PCA: Implement Principal Component Analysis (PCA) to reduce the high-dimensional clustered data to two principal components. This step simplifies the dataset while retaining essential features necessary for understanding the clustering patterns.\n",
    "2. Visualization of Clusters: After reducing the dimensions, use a scatter plot to visualize the clusters in this new two-dimensional space.\n",
    "Plot Customization: Assign different colors to each cluster for clarity, label the axes as 'Principal Component 1' and 'Principal Component 2', and include a legend indicating the cluster numbers.\n",
    "3. Interpretation of Results: Analyze the scatter plot to identify any distinct groupings or patterns that emerge among the clusters. Look for overlaps, distinct separations, or any other notable characteristics in the distribution of the clusters.\n",
    "\n",
    "This task is aimed at providing a visual representation of the clustering results in a simpler, two-dimensional space, making it easier to interpret and analyze the relationships between different clusters. The outcome should be a clear and informative scatter plot that offers insights into the structure and distribution of the clustered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa76281",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5921b4",
   "metadata": {},
   "source": [
    "## Reflection: \n",
    "Provide a brief reflection on what you learned, the challenges you faced, and how you overcame them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5144ea26",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
